{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f116fde5ad0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk \n",
    "import pickle\n",
    "import swifter \n",
    "%matplotlib inline\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import time \n",
    "import scipy\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9375, 8)\n",
      "(9375, 3)\n",
      "Data Created\n"
     ]
    }
   ],
   "source": [
    "### CONFIG ###\n",
    "# WORDS\n",
    "valid_tags = ['JJ','JJR','JJS','NN','NNS','NNP','NNPS','RB','RBR','RBS','VB','VBD','VBG','VBN','VBP','VBZ','WP','WP$','WRB']\n",
    "\n",
    "data = pd.read_csv(\"wiki_movie_plots_deduped.csv\")\n",
    "data = pd.concat([\n",
    "    data[data['Genre'].isin(['action', 'thriller', 'romance', 'war', 'horror', 'comedy', 'adventure', 'crime', 'sport'])]\n",
    "    #data[data['Genre'].isin(['comedy'])].head(1000)\n",
    "])\n",
    "print(data.shape)\n",
    "data = data[['Genre', 'Plot']]\n",
    "data = data[data['Genre'] != 'unknown']\n",
    "data['Genre'] = data['Genre'].map(lambda x: str(x).lower().strip().split(','))\n",
    "unique_genres = np.unique([y.strip() for x in data['Genre'].values.tolist() for y in x if y != '' and y != ' '])\n",
    "\n",
    "def get_genre_array(x, unique_genres):\n",
    "    cur_array = np.zeros(len(unique_genres))\n",
    "    for cur_genre in x:\n",
    "        cur_genre = cur_genre.strip()\n",
    "        if cur_genre != '' and cur_genre != ' ':\n",
    "            cur_array[np.where(unique_genres==cur_genre)[0][0]]=1\n",
    "    return cur_array\n",
    "data['genre_array'] = data['Genre'].map(lambda x: get_genre_array(x, unique_genres))\n",
    "\n",
    "data['Plot'] = data['Plot'].map(lambda x: str(x).lower())\n",
    "print(data.shape)\n",
    "\n",
    "def refine_tokens(cur_plot, valid_tags, stopwords):\n",
    "    sentences = cur_plot.split('.')\n",
    "    filtered_sentences = []\n",
    "    for cur_sentence in sentences:\n",
    "        words_list = nltk.word_tokenize(cur_sentence)\n",
    "        words_list = [w for w in words_list if w not in stopwords.words()] \n",
    "        words_list = nltk.pos_tag(words_list)\n",
    "        words_list = [x[0] for x in words_list if x[1] in valid_tags]\n",
    "        filtered_sentences.append(' '.join(words_list))\n",
    "    return ' '.join(filtered_sentences)\n",
    "print(\"Data Created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13dff16d43be4d49b67ad7453312d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dask Apply:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 57s, sys: 22.7 s, total: 5min 19s\n",
      "Wall time: 1h 9min 4s\n",
      "Write the data\n",
      "Write the data\n",
      "Features prepared\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "## DATA 1\n",
    "########################\n",
    "\n",
    "%time data['plot_array'] = data.swifter.apply(lambda x: refine_tokens(x['Plot'], valid_tags, stopwords), axis=1)\n",
    "\n",
    "print(\"Write the data\")\n",
    "pickle.dump(data, open(\"processed_data.pickle\", \"wb\"))\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000, ngram_range=(1,3), max_df=50, min_df=1)\n",
    "data['plot_array'] = vectorizer.fit_transform(data['plot_array'].values.tolist()).todense().tolist()\n",
    "temp_arr = np.array(data['plot_array'].values.tolist())\n",
    "temp_arr[temp_arr > 1] = 1\n",
    "data['plot_array'] = temp_arr.tolist()\n",
    "\n",
    "print(\"Write the data\")\n",
    "pickle.dump(data, open(\"processed_data.pickle\", \"wb\"))\n",
    "pickle.dump(vectorizer, open(\"vectorizer.pickle\", \"wb\"))\n",
    "\n",
    "del(temp_arr)\n",
    "gc.collect()\n",
    "\n",
    "print(\"Features prepared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESTART\n",
    "data = pickle.load(open(\"processed_data.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'horror',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'war',\n",
       " 'war',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'horror',\n",
       " 'romance',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'war',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'romance',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'action',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'crime',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'war',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'horror',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'action',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'crime',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'action',\n",
       " 'war',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'war',\n",
       " 'war',\n",
       " 'war',\n",
       " 'war',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'horror',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'romance',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'war',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'comedy',\n",
       " 'action',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'crime',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'war',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'thriller',\n",
       " 'comedy',\n",
       " 'comedy',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'horror',\n",
       " 'crime',\n",
       " 'war',\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "########################\n",
    "## DATA 2\n",
    "########################\n",
    "def found(search_word, cur_list):\n",
    "    for cur_word in cur_list:\n",
    "        if search_word in cur_word:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "data = pickle.load(open(\"processed_data.pickle\", \"rb\"))\n",
    "data['is_action_genre'] = data['Genre'].map(lambda x: found('action', x))\n",
    "print(data['is_action_genre'].value_counts())\n",
    "gc.collect()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture\n",
    "\n",
    "class classifier_model(nn.Module):\n",
    "    def __init__(self, label_count, initial_features):\n",
    "        super(classifier_model, self).__init__()\n",
    "        self.l1 = nn.Linear(initial_features, 512)\n",
    "        self.l2 = nn.Linear(512, 256)\n",
    "        self.l3 = nn.Linear(256, 128)\n",
    "        self.l4 = nn.Linear(128, 64)\n",
    "        self.l5 = nn.Linear(64, label_count)\n",
    "        self.b1 = nn.BatchNorm1d(512)\n",
    "        self.b2 = nn.BatchNorm1d(256)\n",
    "        self.b3 = nn.BatchNorm1d(128)\n",
    "        self.b4 = nn.BatchNorm1d(64)\n",
    "        self.b5 = nn.BatchNorm1d(label_count)\n",
    "        #self.sigm = nn.Sigmoid()\n",
    "        self.smax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.l1d = self.l1(x)\n",
    "        self.b1d = self.b1(self.l1d)\n",
    "        self.l2d = self.l2(F.leaky_relu(self.b1d))\n",
    "        self.b2d = self.b2(self.l2d)\n",
    "        self.l3d = self.l3(F.leaky_relu(self.b2d))\n",
    "        self.b3d = self.b3(self.l3d)\n",
    "        self.l4d = self.l4(F.leaky_relu(self.b3d))\n",
    "        self.b4d = self.b4(self.l4d)\n",
    "        self.l5d = self.l5(F.leaky_relu(self.b4d))\n",
    "        self.b5d = self.b5(self.l5d)\n",
    "        self.smaxd = self.smax(self.b5d)\n",
    "        return self.smaxd\n",
    "    \n",
    "print(\"Model created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model object created and config also created\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "# MODEL\n",
    "#######################\n",
    "\n",
    "# Config    \n",
    "num_epochs = 2000\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "label_count = 8\n",
    "model = classifier_model(label_count, 10000).cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "data_input = Variable(torch.from_numpy(np.array(data['plot_array'].values.tolist()).astype(np.float32))).cuda()\n",
    "#data_output = Variable(torch.from_numpy(np.array(data['is_action_genre'].values.tolist()).astype(np.float32))).cuda()\n",
    "data_output = Variable(torch.from_numpy(np.array(data['genre_array'].values.tolist()).astype(np.float32))).cuda()\n",
    "batches = int(data_input.size()[0]/batch_size)\n",
    "\n",
    "print(\"Model object created and config also created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21686/3070702456.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.smaxd = self.smax(self.b5d)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [0/2000], loss:0.2908 time_taken: 5.230108022689819\n",
      "Writing the mode at epoch 0\n",
      "epoch [10/2000], loss:0.0045 time_taken: 31.350057363510132\n",
      "epoch [20/2000], loss:0.0006 time_taken: 56.38586926460266\n",
      "epoch [30/2000], loss:0.0003 time_taken: 81.49875998497009\n",
      "epoch [40/2000], loss:0.0001 time_taken: 106.5484082698822\n",
      "epoch [50/2000], loss:0.0027 time_taken: 131.61134839057922\n",
      "epoch [60/2000], loss:0.0002 time_taken: 156.69063663482666\n",
      "epoch [70/2000], loss:0.0001 time_taken: 181.82100105285645\n",
      "epoch [80/2000], loss:0.0000 time_taken: 206.96115589141846\n",
      "epoch [90/2000], loss:0.0000 time_taken: 232.20207691192627\n",
      "epoch [100/2000], loss:0.0000 time_taken: 259.6808650493622\n",
      "Writing the mode at epoch 100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21686/2622049264.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcur_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcur_batch\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_batch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcur_batch\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcur_batch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/anantgupta/CCEC7C9EEC7C850C1/ubuntu_softwares/ananconda3/envs/python3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21686/3070702456.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleaky_relu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/anantgupta/CCEC7C9EEC7C850C1/ubuntu_softwares/ananconda3/envs/python3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/anantgupta/CCEC7C9EEC7C850C1/ubuntu_softwares/ananconda3/envs/python3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/anantgupta/CCEC7C9EEC7C850C1/ubuntu_softwares/ananconda3/envs/python3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "start_time = time.time()\n",
    "for epoch in range(100000):\n",
    "    for cur_batch in range(batches):\n",
    "        model.zero_grad()\n",
    "        model_output = model(data_input[batch_size*cur_batch : batch_size * (cur_batch+1)]).view(batch_size, label_count)\n",
    "        loss = criterion(model_output, data_output[batch_size*cur_batch : batch_size * (cur_batch+1)])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print('epoch [{}/{}], loss:{:.4f} time_taken: {}'.format(epoch, num_epochs, loss, time.time() - start_time))\n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Writing the mode at epoch {0}\".format(epoch))\n",
    "        torch.save(model, \"self_model_action_noaction\")\n",
    "torch.save(model, \"self_model_action_noaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21686/3070702456.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  self.smaxd = self.smax(self.b5d)\n"
     ]
    }
   ],
   "source": [
    "# RESTART\n",
    "model = torch.load(\"self_model_action_noaction\")\n",
    "\n",
    "# Analysis of concepts within the triggers\n",
    "data_input = Variable(torch.from_numpy(np.array(data['plot_array'].values.tolist()).astype(np.float32))).cuda()\n",
    "model_output = model(data_input)\n",
    "temp_data = np.concatenate(\n",
    "    (model.l1d.cpu().detach().numpy(),\n",
    "     model.b1d.cpu().detach().numpy(),\n",
    "     model.l2d.cpu().detach().numpy(),\n",
    "     model.b2d.cpu().detach().numpy(),\n",
    "     model.l3d.cpu().detach().numpy(),\n",
    "     model.b3d.cpu().detach().numpy(),\n",
    "     model.l4d.cpu().detach().numpy(),\n",
    "     model.b4d.cpu().detach().numpy(),\n",
    "     model.l5d.cpu().detach().numpy(),\n",
    "     model.b5d.cpu().detach().numpy()\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "temp_data = pd.DataFrame(temp_data)\n",
    "temp_data = temp_data.fillna(0)\n",
    "temp_data = round(temp_data, 2)\n",
    "temp_data.to_csv(\"activation_data_20211115.csv\", index=False)\n",
    "\n",
    "# Same output, earlier layers\n",
    "temp_data = np.concatenate(\n",
    "    (model.l1d.cpu().detach().numpy(),\n",
    "     model.b1d.cpu().detach().numpy(),\n",
    "     model.l2d.cpu().detach().numpy(),\n",
    "     model.b2d.cpu().detach().numpy(),\n",
    "     model.l3d.cpu().detach().numpy(),\n",
    "     model.b3d.cpu().detach().numpy()\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "temp_data = pd.DataFrame(temp_data)\n",
    "temp_data = temp_data.fillna(0)\n",
    "temp_data = round(temp_data, 2)\n",
    "temp_data.to_csv(\"activation_data_20211115_earlier_layers.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1702\n",
      "17    1276\n",
      "8     1093\n",
      "3      564\n",
      "18     520\n",
      "11     485\n",
      "15     475\n",
      "2      467\n",
      "4      460\n",
      "9      459\n",
      "14     297\n",
      "12     260\n",
      "16     212\n",
      "13     189\n",
      "19     188\n",
      "5      185\n",
      "7      185\n",
      "6      176\n",
      "1       96\n",
      "10      86\n",
      "Name: cluster_kmeans, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Simple Kmeans Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=20, random_state=42).fit(temp_data.drop(columns=[x for x in temp_data.columns.values if 'cluster' in str(x)]).values)\n",
    "temp_data['cluster_kmeans'] = kmeans.labels_\n",
    "print(temp_data['cluster_kmeans'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1783</th>\n",
       "      <th>1784</th>\n",
       "      <th>1785</th>\n",
       "      <th>1786</th>\n",
       "      <th>1787</th>\n",
       "      <th>1788</th>\n",
       "      <th>1789</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>cluster_dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.56</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.77</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.11</td>\n",
       "      <td>-0.78</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9370</th>\n",
       "      <td>-0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.62</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9371</th>\n",
       "      <td>-1.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9373</th>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>0.14</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.54</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.34</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.46</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9374</th>\n",
       "      <td>0.63</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9375 rows  1793 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1     2     3     4     5     6     7     8     9  ...  1783  \\\n",
       "0    -0.29  0.03  0.13  0.49  0.13  0.17 -0.06 -0.16 -0.06 -0.44  ... -0.47   \n",
       "1     0.56 -0.53 -0.71  0.09  0.05 -0.56  1.23  0.06  0.20 -0.30  ... -0.11   \n",
       "2     0.18 -0.23  0.11  0.14  0.32  0.99  0.59  0.12 -0.46  0.41  ... -0.24   \n",
       "3    -0.03 -0.48  0.09  0.04  0.16  0.11  0.08 -0.05 -0.45  0.12  ... -0.29   \n",
       "4     1.11 -0.78  0.63  0.04 -0.30  0.28  0.93  0.12  0.02 -0.10  ...  0.01   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "9370 -0.96  0.21  0.14 -0.02 -0.21 -0.32  0.06 -0.45 -0.09 -0.38  ...  0.23   \n",
       "9371 -1.04  0.25  0.08 -0.02  0.05 -0.00 -0.29  0.08 -0.07 -0.37  ...  0.44   \n",
       "9372 -0.30 -0.98 -0.37  0.23 -0.32 -0.05 -0.38 -0.15  0.09 -0.58  ...  0.54   \n",
       "9373 -0.32 -0.19  0.22  0.14 -0.04 -0.32  0.33  0.09 -0.36  0.14  ... -0.63   \n",
       "9374  0.63 -0.47 -0.07  0.20  0.13 -0.34  0.19  0.10 -0.06  0.17  ...  0.42   \n",
       "\n",
       "      1784  1785  1786  1787  1788  1789  1790  1791  cluster_dbscan  \n",
       "0     0.80 -0.25 -0.25 -0.01  0.15  0.18 -0.38  0.10              -1  \n",
       "1    -0.25 -0.19 -0.59  0.27  0.29 -0.01  0.26 -0.37              -1  \n",
       "2     0.80 -0.31 -0.58  0.10  0.22 -0.47  0.10 -0.33              -1  \n",
       "3     0.77 -0.16 -0.15  0.08  0.14 -0.12 -0.51  0.24              -1  \n",
       "4     0.14 -0.23 -0.25  0.01  0.37  0.78  0.21  0.03              -1  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...             ...  \n",
       "9370 -0.44  0.52  0.54  0.71 -0.26 -0.22  0.25  0.62              -1  \n",
       "9371  0.64 -0.07 -0.30  0.17  0.40 -0.71 -0.32  0.25              -1  \n",
       "9372 -0.48  0.28  0.41  0.46 -0.06  0.54 -0.11  0.72              -1  \n",
       "9373  0.54 -0.04 -0.22  0.34 -0.01 -0.15  0.10  0.46              -1  \n",
       "9374  0.38  0.28 -0.05  0.47  0.01 -0.07  0.19  0.76              -1  \n",
       "\n",
       "[9375 rows x 1793 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We might have to do some mixing and matching not all columns will be useful.  For a group of columns we will try to find the combinations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    9295\n",
      " 0      80\n",
      "Name: cluster_dbscan, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "def perform_dbscan(temp_data, cluster_name)\n",
    "    clustering = DBSCAN(eps=1, min_samples=10).fit(temp_data.drop(columns=[x for x in temp_data.columns.values if 'cluster' in str(x)]).values)\n",
    "    temp_data[cluster_name] = clustering.labels_\n",
    "    return temp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1784</th>\n",
       "      <th>1785</th>\n",
       "      <th>1786</th>\n",
       "      <th>1787</th>\n",
       "      <th>1788</th>\n",
       "      <th>1789</th>\n",
       "      <th>1790</th>\n",
       "      <th>1791</th>\n",
       "      <th>cluster_kmeans</th>\n",
       "      <th>cluster_dbscan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.27</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  1794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1     2    3     4     5     6     7     8     9  ...  1784  \\\n",
       "8768 -0.73  0.5 -0.11 -0.2  0.15  0.18  0.13 -0.27  0.11 -0.24  ...  0.63   \n",
       "9152 -0.73  0.5 -0.11 -0.2  0.15  0.18  0.13 -0.27  0.11 -0.24  ...  0.63   \n",
       "\n",
       "      1785  1786  1787  1788  1789  1790  1791  cluster_kmeans  cluster_dbscan  \n",
       "8768  0.15  0.49  0.25  0.17 -0.18  0.07  -0.8               0              63  \n",
       "9152  0.15  0.49  0.25  0.17 -0.18  0.07  -0.8               0              63  \n",
       "\n",
       "[2 rows x 1794 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data[temp_data['cluster_dbscan']==63]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
